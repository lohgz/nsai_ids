{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move two dirs up\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# set path\n",
    "base_path = os.getcwd()\n",
    "path = os.path.join(base_path, \"data\", \"output\", \"concatenated.csv\")\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# statistical numbers\n",
    "num_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# compute metrics\n",
    "mins    = num_df.min()\n",
    "maxs    = num_df.max()\n",
    "nunique = num_df.nunique()\n",
    "sums    = num_df.sum()\n",
    "\n",
    "# combine into summary table\n",
    "stats = pd.DataFrame({\n",
    "    'min':    mins,\n",
    "    'max':    maxs,\n",
    "    'nunique': nunique,\n",
    "    'sum':    sums\n",
    "})\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "cols = [\n",
    "    'fwd_URG_flag_count',\n",
    "    'bwd_URG_flag_count',\n",
    "    'flow_CWR_flag_count',\n",
    "    'flow_ECE_flag_count'\n",
    "]\n",
    "\n",
    "# drop constants\n",
    "df = df.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print some initial counts and plots\n",
    "\n",
    "# chart 1: attack vs benign\n",
    "attack_counts = df['attack'].value_counts()\n",
    "plt.figure()\n",
    "attack_counts.plot(kind='bar')\n",
    "plt.title('Attack vs Benign')\n",
    "plt.xlabel('Attack')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print(\"Attack vs Benign counts:\\n\", attack_counts, \"\\n\")\n",
    "\n",
    "# chart 2: service distribution\n",
    "service_counts = df['service'].value_counts()\n",
    "plt.figure()\n",
    "service_counts.plot(kind='bar')\n",
    "plt.title('Service Distribution')\n",
    "plt.xlabel('Service')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print(\"Service distribution counts:\\n\", service_counts)\n",
    "\n",
    "# chart 3: attack distribution\n",
    "attack_counts = df['attack_type'].value_counts()\n",
    "plt.figure()\n",
    "attack_counts.plot(kind='bar')\n",
    "plt.title('Attack vs Benign')\n",
    "plt.xlabel('Attack')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print(\"Attack type counts:\\n\", attack_counts, \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> “The attacks revshell and Server-Side Request Forgery (SSRF) are usually only successful when the victim server creates a new connection  \n",
    "> to a host specified in one of the attacks. This results in that proper detection is only guaranteed when at least two flows are analyzed.”  \n",
    "> — Lanfer *et al.*, 2025  \n",
    "\n",
    "Because this pipeline performs **flow-level classification** , it cannot reliably detect:\n",
    "\n",
    "- Reverse Shell attacks  \n",
    "  - `revshell_http`  \n",
    "  - `revshell_https`  \n",
    "- Server-Side Request Forgery (SSRF) attacks  \n",
    "  - `ssrf_http`  \n",
    "  - `ssrf_https`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attacks to exclude\n",
    "exclude_attacks = ['revshell_https', 'revshell_http', 'ssrf_https', \n",
    "                   'ssrf_http', 'xss_http', 'xss_https', 'smtp_enum'] # remove smtp_enum as well due to its very low sample count\n",
    "\n",
    "# df without excluded attacks\n",
    "df = df[~df['attack_type'].isin(exclude_attacks)].copy()\n",
    "\n",
    "# map to merge http and https and similar attacks\n",
    "merge_map = {\n",
    "    'bruteforce_http': 'bruteforce',\n",
    "    'bruteforce_https': 'bruteforce',\n",
    "    'sql_injection_http': 'sql_injection',\n",
    "    'sql_injection_https': 'sql_injection',\n",
    "    'dos_http': 'dos',\n",
    "    'dos_https': 'dos',\n",
    "    'ssh_login_successful': 'ssh_login',\n",
    "    'hostsweep_Pn': 'hostsweep',\n",
    "    'hostsweep_sn': 'hostsweep'\n",
    "}\n",
    "\n",
    "# merge attacks\n",
    "df['attack_type'] = df['attack_type'].replace(merge_map)\n",
    "\n",
    "# chart 4: attack distribution v2\n",
    "attack_counts = df['attack_type'].value_counts()\n",
    "plt.figure()\n",
    "attack_counts.plot(kind='bar')\n",
    "plt.title('Attack vs Benign')\n",
    "plt.xlabel('Attack')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print(\"Attack type counts:\\n\", attack_counts, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only numeric columns\n",
    "num_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# compute correlation matrix\n",
    "corr_matrix = num_df.corr()\n",
    "\n",
    "# plot heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(corr_matrix, aspect='auto', interpolation='nearest', cmap='coolwarm')\n",
    "plt.colorbar(label='r')\n",
    "plt.xticks(ticks=np.arange(len(corr_matrix.columns)), labels=corr_matrix.columns, rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(corr_matrix.index)), labels=corr_matrix.index)\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# mask out the upper triangle and the diagonal\n",
    "mask = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "\n",
    "# stack into a series of pairwise correlations\n",
    "corr_pairs = corr_matrix.where(mask).stack()\n",
    "\n",
    "# select those above 0.9\n",
    "high_corr = corr_pairs[abs(corr_pairs) > 0.9].sort_values(ascending=False)\n",
    "\n",
    "print(\"Feature pairs with absoulte r > 0.9:\\n\")\n",
    "for (feat1, feat2), r in high_corr.items():\n",
    "    print(f\"{feat1:30s} <-> {feat2:30s} : r = {r:.3f}\")\n",
    "\n",
    "# extract all feature names from the index\n",
    "feat1 = high_corr.index.get_level_values(0)\n",
    "feat2 = high_corr.index.get_level_values(1)\n",
    "\n",
    "# build a sorted list of unique features\n",
    "high_corr_features = sorted(set(feat1).union(feat2))\n",
    "\n",
    "print(\"Features appearing in any |r| > 0.9 pair:\")\n",
    "print(high_corr_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    'bwd_data_pkts_tot',\n",
    "    'bwd_pkts_per_sec',\n",
    "    'flow_pkts_per_sec',\n",
    "    'fwd_header_size_tot',\n",
    "    'fwd_header_size_max',\n",
    "    'bwd_header_size_max',\n",
    "    'flow_FIN_flag_count',\n",
    "    'flow_SYN_flag_count',\n",
    "    'flow_ACK_flag_count',\n",
    "    'bwd_init_window_size'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_zero_day_splits(df,\n",
    "                         splits: dict,\n",
    "                         n_benign_zero_day: int = 220000,\n",
    "                         train_samples: tuple = (500000, 500000),\n",
    "                         test_samples: tuple = (199800, 200),\n",
    "                         random_state: int = 1304):\n",
    "\n",
    "    \n",
    "    for split_name, zero_day_attacks in splits.items():\n",
    "        # split off attack flows for test\n",
    "        df_test = df[df['attack_type'].isin(zero_day_attacks)].copy()\n",
    "        df_train = df[~df['attack_type'].isin(zero_day_attacks)].copy()\n",
    "        \n",
    "        # sample benigns for test\n",
    "        df_train_benign = df_train[df_train['attack_type'] == 'benign']\n",
    "        df_benign_zero_day = df_train_benign.sample(\n",
    "            n=n_benign_zero_day, random_state=random_state\n",
    "        )\n",
    "        df_train = df_train.drop(df_benign_zero_day.index)\n",
    "        df_test = pd.concat([df_test, df_benign_zero_day])\n",
    "        \n",
    "        # binary encode attack column\n",
    "        mapping = {'benign': 0, 'attack': 1}\n",
    "        df_train['attack'] = df_train['attack'].map(mapping)\n",
    "        df_test['attack']  = df_test['attack'].map(mapping)\n",
    "        \n",
    "        # balance & shuffle train\n",
    "        n_benign_tr, n_attack_tr = train_samples\n",
    "        benign_train = df_train[df_train['attack'] == 0].sample(n=n_benign_tr, random_state=random_state)\n",
    "        attack_train = df_train[df_train['attack'] == 1].sample(n=n_attack_tr, random_state=random_state)\n",
    "        df_train_final = pd.concat([benign_train, attack_train]).sample(frac=1, random_state=random_state)\n",
    "        \n",
    "        # balance & shuffle test\n",
    "        n_benign_te, n_attack_te = test_samples\n",
    "        benign_test = df_test[df_test['attack'] == 0].sample(n=n_benign_te, random_state=random_state)\n",
    "        attack_test = df_test[df_test['attack'] == 1].sample(n=n_attack_te, random_state=random_state)\n",
    "        df_test_final = pd.concat([benign_test, attack_test]) .sample(frac=1, random_state=random_state)\n",
    "        \n",
    "        # save to csv\n",
    "        train_path = os.path.join(base_path, \"data\", \"output\", f\"train_{split_name}.csv\")\n",
    "        test_path  = os.path.join(base_path, \"data\", \"output\", f\"test_{split_name}.csv\")\n",
    "        df_train_final.to_csv(train_path, index=False)\n",
    "        df_test_final.to_csv(test_path,  index=False)\n",
    "        \n",
    "        # report\n",
    "        print(f\"Split '{split_name}' -> train: {df_train_final.shape}, \"\n",
    "              f\"test: {df_test_final.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    'split_1': ['ftp_login', 'ftp_version', 'smtp_version'],\n",
    "    'split_2': ['sql_injection', 'dos', 'ssh_login']\n",
    "}\n",
    "\n",
    "make_zero_day_splits(df, splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
